{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "PROJECT_DIR = os.path.dirname(os.getcwd())\n",
    "if PROJECT_DIR not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_DIR)\n",
    "\n",
    "from chord_recognition.cache import HDF5Cache\n",
    "from chord_recognition.models.deep_harmony import deep_harmony\n",
    "from chord_recognition.dataset import ChromaDataset, prepare_datasource, undersample_dataset, StackedFrameDataset\n",
    "from chord_recognition.utils import Rescale, one_hot\n",
    "from chord_recognition.train import get_weighted_random_sampler, Solver\n",
    "from chord_recognition.ann_utils import convert_annotation_matrix, get_chord_labels\n",
    "from chord_recognition.evaluate import plot_confusion_matrix\n",
    "from chord_recognition.predict import forward\n",
    "\n",
    "\n",
    "torch.manual_seed(2020)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (14, 5)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exp6\n",
    "window_size = 8192\n",
    "hop_length = 4410\n",
    "context_size = 7\n",
    "T = 20\n",
    "S = 8\n",
    "\n",
    "#ds = prepare_datasource(('beatles', 'zweieck', 'queen', 'robbie_williams'))\n",
    "ds = prepare_datasource(('beatles',))[:100]\n",
    "cache = HDF5Cache(os.path.join(PROJECT_DIR, 'spectrogram_ann_cache.hdf5'))\n",
    "dataset = StackedFrameDataset(\n",
    "    datasource=ds,\n",
    "    T=T,\n",
    "    S=S,\n",
    "    context_size=context_size,\n",
    "    window_size=window_size,\n",
    "    hop_length=hop_length,\n",
    "    cache=cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train/val\n",
    "indices = np.arange(len(dataset))\n",
    "idx_train, idx_val = train_test_split(\n",
    "    indices, test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TRAIN_MEAN, TRAIN_STD\n",
    "X_train_temp = np.hstack([xi.reshape(xi.shape[1], xi.shape[0] * xi.shape[2])\n",
    "                          for xi,_ in dataset[idx_train]])\n",
    "TRAIN_MEAN = X_train_temp.mean(axis=1).reshape(-1, 1)\n",
    "TRAIN_STD = X_train_temp.std(axis=1).reshape(-1, 1)\n",
    "\n",
    "del X_train_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Subset(dataset, idx_train)\n",
    "val_data = Subset(dataset, idx_val)\n",
    "train_data.dataset.transform = transforms.Compose([\n",
    "    # Rescale inputs to have a mean of 0 and std of 1\n",
    "    # It must speed up the convergence\n",
    "    Rescale(TRAIN_MEAN, TRAIN_STD),\n",
    "])\n",
    "val_data.dataset.transform = transforms.Compose([\n",
    "    # Rescale inputs to have a mean of 0 and std of 1\n",
    "    # It must speed up the convergence\n",
    "    Rescale(TRAIN_MEAN, TRAIN_STD),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "# Split dataset into train/val datasets\n",
    "loader_train = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=0)\n",
    "loader_val = DataLoader(\n",
    "    dataset=val_data,\n",
    "    num_workers=0,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": loader_train,\n",
    "    \"val\": loader_val\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = deep_harmony()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "learning_rate = 1e-2\n",
    "epochs=10\n",
    "weight_decay = 0\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer,\n",
    "    max_lr=1e-3,\n",
    "    steps_per_epoch=len(loader_train),\n",
    "    epochs=epochs,\n",
    "    anneal_strategy='linear',\n",
    ")\n",
    "\n",
    "solver = Solver(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    dataloaders=dataloaders,\n",
    "    scheduler=scheduler,\n",
    "    trained_model_name=\"deep_auditory_v2_exp6_1.pth\",\n",
    "    epochs=epochs)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "model = deep_auditory_v2(pretrained=True, model_name='deep_auditory_v2_exp6.pth')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = (i for i,_ in loader_val)\n",
    "y_hat_matrix = forward(model, val_loader, device, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_matrix = y_hat_matrix.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_hat_matrix, 1)\n",
    "y_pred = one_hot(y_pred, 25)\n",
    "y_pred = convert_annotation_matrix(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "y_matrix = one_hot(y_val, 25)\n",
    "y_true = convert_annotation_matrix(y_matrix)\n",
    "\n",
    "labels = get_chord_labels(nonchord=True)\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "print(cm)\n",
    "\n",
    "plot_confusion_matrix(cm, labels, fontsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
