{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import mir_eval\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, SequentialSampler, ConcatDataset\n",
    "\n",
    "from chord_recognition.dataset import AudioDataset\n",
    "from chord_recognition.metrics import compute_eval_measures\n",
    "from chord_recognition.cnn import model\n",
    "from chord_recognition.predict import predict_annotations, model, device, annotate_audio\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chord_dataset = AudioDataset(audio_dir=\"data/robbie_williams/mp3/\",\n",
    "                             ann_dir=\"data/robbie_williams/chordlabs/\",\n",
    "                            window_size=8192, hop_length=4096)\n",
    "# chord_dataset = AudioDataset(audio_dir=\"data/queen/mp3/\",\n",
    "#                              ann_dir=\"data/queen/chordlabs/\",\n",
    "#                              window_size=8192, hop_length=4096)\n",
    "# chord_dataset = AudioDataset(audio_dir=\"data/beatles/mp3s-32k/\",\n",
    "#                      ann_dir=\"data/beatles/chordlabs/\",\n",
    "#                      window_size=8192, hop_length=4096)\n",
    "# chord_dataset = ConcatDataset([chord_dataset, queen])\n",
    "loader_chord = DataLoader(chord_dataset, batch_size=None, num_workers=0)\n",
    "sampler = SequentialSampler(chord_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_chords(dataloader, model, device, batch_size=32,\n",
    "                    drop_last=False):\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    total_R = total_P = total_F = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for idx in dataloader:\n",
    "        sample = dataloader.data_source[idx]\n",
    "        sample_name = sample['sample']\n",
    "        chromagram = sample['chromagram']\n",
    "        \n",
    "        result = predict_annotations(chromagram, model, device, batch_size=batch_size)\n",
    "        ann_matrix = sample['ann_matrix']\n",
    "        count += 1\n",
    "        \n",
    "        P, R, F1, TP, FP, FN = compute_eval_measures(ann_matrix, result)\n",
    "        total_R += R\n",
    "        total_P += P\n",
    "        total_F += F1\n",
    "        title = f'Eval: (N=%d, TP=%d, FP=%d, FN=%d, P=%.3f, R=%.3f, F=%.3f) - {sample_name}' % (result.shape[1], TP, FP, FN, P,R,F1)\n",
    "        print(title)\n",
    "    total_R /= count\n",
    "    total_P /= count\n",
    "    total_F /= count\n",
    "    print(f'Total R: {total_R}')\n",
    "    print(f'Total P: {total_P}')\n",
    "    print(f'Total F: {total_F}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_chords(dataloader, model, device, batch_size=32, result_dir='results/robbie_williams'):\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    for idx in dataloader:\n",
    "        sample = dataloader.data_source[idx]\n",
    "        sample_name = sample['sample']\n",
    "        print(sample_name)\n",
    "        Fs = sample['Fs']\n",
    "        audio_waveform = sample['audio_waveform']\n",
    "        \n",
    "        annotations = annotate_audio(audio_waveform, Fs, ext_minor=':min')\n",
    "        save_annotations(annotations, sample_name, result_dir=result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_annotations(annotations, filename, result_dir='results'):    \n",
    "    path = os.path.join(result_dir, filename)\n",
    "    dirname = os.path.dirname(path)\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    \n",
    "    with open(path, 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=' ')\n",
    "        for ann in annotations:\n",
    "            writer.writerow(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(annotation_files, prediction_files):\n",
    "    assert len(annotation_files) == len(prediction_files)\n",
    "    assert len(annotation_files) > 0\n",
    "    import mir_eval\n",
    "\n",
    "    scores = []\n",
    "    total_length = 0.\n",
    "\n",
    "    for af, pf in zip(annotation_files, prediction_files):\n",
    "        ann_int, ann_lab = mir_eval.io.load_labeled_intervals(af)\n",
    "        pred_int, pred_lab = mir_eval.io.load_labeled_intervals(pf)\n",
    "\n",
    "        # we assume that the end-time of the last annotated label is the\n",
    "        # length of the song\n",
    "        song_length = ann_int[-1][1]\n",
    "        total_length += song_length\n",
    "\n",
    "        scores.append(\n",
    "            (pf, song_length,\n",
    "             mir_eval.chord.evaluate(ann_int, ann_lab, pred_int, pred_lab))\n",
    "        )\n",
    "\n",
    "    return scores, total_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: (N=2527, TP=1699, FP=828, FN=708, P=0.672, R=0.706, F=0.689) - 1997-Life Thru a Lens/01-Lazy Days\n",
      "Eval: (N=2020, TP=1138, FP=882, FN=700, P=0.563, R=0.619, F=0.590) - 1997-Life Thru a Lens/02-Life Thru A Lens\n",
      "Eval: (N=2315, TP=635, FP=1680, FN=1436, P=0.274, R=0.307, F=0.290) - 1997-Life Thru a Lens/03-Ego A Go Go\n",
      "Eval: (N=2854, TP=2061, FP=793, FN=655, P=0.722, R=0.759, F=0.740) - 1997-Life Thru a Lens/04-Angels\n",
      "Eval: (N=2513, TP=1365, FP=1148, FN=1148, P=0.543, R=0.543, F=0.543) - 1997-Life Thru a Lens/05-South Of The Border\n",
      "Eval: (N=2516, TP=1165, FP=1351, FN=874, P=0.463, R=0.571, F=0.512) - 1997-Life Thru a Lens/06-Old Before I Die\n",
      "Eval: (N=2302, TP=1155, FP=1147, FN=901, P=0.502, R=0.562, F=0.530) - 1997-Life Thru a Lens/07-One Of God's Better People\n",
      "Eval: (N=2821, TP=1707, FP=1114, FN=473, P=0.605, R=0.783, F=0.683) - 1997-Life Thru a Lens/08-Let Me Entertain You\n",
      "Eval: (N=2544, TP=968, FP=1576, FN=372, P=0.381, R=0.722, F=0.498) - 1997-Life Thru a Lens/09-Killing Me\n",
      "Eval: (N=2535, TP=1125, FP=1410, FN=1245, P=0.444, R=0.475, F=0.459) - 1997-Life Thru a Lens/10-Clean\n",
      "Eval: (N=9154, TP=7234, FP=1920, FN=781, P=0.790, R=0.903, F=0.843) - 1997-Life Thru a Lens/11-Baby Girl Window\n",
      "Eval: (N=3008, TP=2083, FP=925, FN=865, P=0.692, R=0.707, F=0.699) - 1998-I've Been Expecting You/01-Strong\n",
      "Eval: (N=3337, TP=1122, FP=2215, FN=1527, P=0.336, R=0.424, F=0.375) - 1998-I've Been Expecting You/02-No Regrets\n",
      "Eval: (N=2647, TP=876, FP=1771, FN=1771, P=0.331, R=0.331, F=0.331) - 1998-I've Been Expecting You/03-Millennium\n",
      "Eval: (N=2611, TP=768, FP=1843, FN=690, P=0.294, R=0.527, F=0.377) - 1998-I've Been Expecting You/04-Phoenix From The Flames\n",
      "Eval: (N=2786, TP=1773, FP=1013, FN=960, P=0.636, R=0.649, F=0.643) - 1998-I've Been Expecting You/05-Win Some Lose Some\n",
      "Eval: (N=2068, TP=437, FP=1631, FN=444, P=0.211, R=0.496, F=0.296) - 1998-I've Been Expecting You/06-Grace\n",
      "Eval: (N=1839, TP=1038, FP=801, FN=530, P=0.564, R=0.662, F=0.609) - 1998-I've Been Expecting You/07-It's Only Us\n",
      "Eval: (N=1997, TP=906, FP=1091, FN=471, P=0.454, R=0.658, F=0.537) - 1998-I've Been Expecting You/08-Heaven From Here\n",
      "Eval: (N=2876, TP=1097, FP=1779, FN=724, P=0.381, R=0.602, F=0.467) - 1998-I've Been Expecting You/09-Karma Killer\n",
      "Eval: (N=2779, TP=150, FP=2629, FN=1529, P=0.054, R=0.089, F=0.067) - 1998-I've Been Expecting You/10-She's The One\n",
      "Eval: (N=2315, TP=927, FP=1388, FN=1040, P=0.400, R=0.471, F=0.433) - 1998-I've Been Expecting You/11-Man Machine\n",
      "Eval: (N=20288, TP=14780, FP=5508, FN=4558, P=0.729, R=0.764, F=0.746) - 1998-I've Been Expecting You/12-These Dreams\n",
      "Eval: (N=3220, TP=1648, FP=1572, FN=1411, P=0.512, R=0.539, F=0.525) - 2000-Sing When You're Winning/01-Let Love Be Your Energy\n",
      "Eval: (N=2182, TP=948, FP=1234, FN=835, P=0.434, R=0.532, F=0.478) - 2000-Sing When You're Winning/02-Better Man\n",
      "Eval: (N=2784, TP=950, FP=1834, FN=560, P=0.341, R=0.629, F=0.442) - 2000-Sing When You're Winning/03-Rock DJ\n",
      "Eval: (N=2783, TP=1730, FP=1053, FN=811, P=0.622, R=0.681, F=0.650) - 2000-Sing When You're Winning/04-Supreme\n",
      "Eval: (N=3087, TP=747, FP=2340, FN=2340, P=0.242, R=0.242, F=0.242) - 2000-Sing When You're Winning/05-Kids\n",
      "Eval: (N=2696, TP=1411, FP=1285, FN=509, P=0.523, R=0.735, F=0.611) - 2000-Sing When You're Winning/06-If It's Hurting You\n",
      "Eval: (N=2925, TP=1683, FP=1242, FN=784, P=0.575, R=0.682, F=0.624) - 2000-Sing When You're Winning/07-Singing For The Lonely\n",
      "Eval: (N=2645, TP=838, FP=1807, FN=676, P=0.317, R=0.554, F=0.403) - 2000-Sing When You're Winning/08-Love Calling Earth\n",
      "Eval: (N=3074, TP=1130, FP=1944, FN=1531, P=0.368, R=0.425, F=0.394) - 2000-Sing When You're Winning/09-Knutsford City Limits\n",
      "Eval: (N=2343, TP=1194, FP=1149, FN=1149, P=0.510, R=0.510, F=0.510) - 2000-Sing When You're Winning/10-Forever Texas\n",
      "Eval: (N=3076, TP=589, FP=2487, FN=2457, P=0.191, R=0.193, F=0.192) - 2000-Sing When You're Winning/11-By All Means Necessary\n",
      "Eval: (N=2594, TP=1405, FP=1189, FN=767, P=0.542, R=0.647, F=0.590) - 2000-Sing When You're Winning/12-The Road To Mandalay\n",
      "Eval: (N=2083, TP=1289, FP=794, FN=691, P=0.619, R=0.651, F=0.635) - 2002-Escapology/01-How Peculiar\n",
      "Eval: (N=2841, TP=1560, FP=1281, FN=755, P=0.549, R=0.674, F=0.605) - 2002-Escapology/02-Feel\n",
      "Eval: (N=3109, TP=1882, FP=1227, FN=751, P=0.605, R=0.715, F=0.656) - 2002-Escapology/03-Something Beautiful\n",
      "Eval: (N=2440, TP=1997, FP=443, FN=443, P=0.818, R=0.818, F=0.818) - 2002-Escapology/04-Monsoon\n",
      "Eval: (N=2818, TP=1847, FP=971, FN=971, P=0.655, R=0.655, F=0.655) - 2002-Escapology/05-Sexed Up\n",
      "Eval: (N=2693, TP=1210, FP=1483, FN=502, P=0.449, R=0.707, F=0.549) - 2002-Escapology/06-Love Somebody\n",
      "Eval: (N=3710, TP=1494, FP=2216, FN=2034, P=0.403, R=0.423, F=0.413) - 2002-Escapology/07-Revolution\n",
      "Eval: (N=2547, TP=1351, FP=1196, FN=1196, P=0.530, R=0.530, F=0.530) - 2002-Escapology/08-Handsome Man\n",
      "Eval: (N=2998, TP=1943, FP=1055, FN=1055, P=0.648, R=0.648, F=0.648) - 2002-Escapology/09-Come Undone\n",
      "Eval: (N=4660, TP=2737, FP=1923, FN=1923, P=0.587, R=0.587, F=0.587) - 2002-Escapology/10-Me and My Monkey\n",
      "Eval: (N=2485, TP=1314, FP=1171, FN=586, P=0.529, R=0.692, F=0.599) - 2002-Escapology/11-Song 3\n",
      "Eval: (N=2672, TP=969, FP=1703, FN=1703, P=0.363, R=0.363, F=0.363) - 2002-Escapology/12-Hot Fudge\n",
      "Eval: (N=2604, TP=676, FP=1928, FN=1928, P=0.260, R=0.260, F=0.260) - 2002-Escapology/13-Cursed\n",
      "Eval: (N=10101, TP=5207, FP=4894, FN=3800, P=0.515, R=0.578, F=0.545) - 2002-Escapology/14a-Nan's Song\n",
      "Eval: (N=1491, TP=800, FP=691, FN=691, P=0.537, R=0.537, F=0.537) - 2002-Escapology/14b-How Peculiar (Reprise)\n",
      "Eval: (N=2396, TP=1821, FP=575, FN=575, P=0.760, R=0.760, F=0.760) - 2005-Intensive Care/01-Ghosts\n",
      "Eval: (N=2978, TP=1341, FP=1637, FN=1637, P=0.450, R=0.450, F=0.450) - 2005-Intensive Care/02-Tripping\n",
      "Eval: (N=2942, TP=2155, FP=787, FN=787, P=0.732, R=0.732, F=0.732) - 2005-Intensive Care/03-Make Me Pure\n",
      "Eval: (N=2487, TP=1726, FP=761, FN=761, P=0.694, R=0.694, F=0.694) - 2005-Intensive Care/04-Spread Your Wings\n",
      "Eval: (N=2988, TP=2222, FP=766, FN=766, P=0.744, R=0.744, F=0.744) - 2005-Intensive Care/05-Advertising Space\n",
      "Eval: (N=3096, TP=2046, FP=1050, FN=1050, P=0.661, R=0.661, F=0.661) - 2005-Intensive Care/06-Please Don't Die\n",
      "Eval: (N=2170, TP=1331, FP=839, FN=839, P=0.613, R=0.613, F=0.613) - 2005-Intensive Care/07-Your Gay Friend\n",
      "Eval: (N=2691, TP=1894, FP=797, FN=656, P=0.704, R=0.743, F=0.723) - 2005-Intensive Care/08-Sin Sin Sin\n",
      "Eval: (N=2748, TP=1715, FP=1033, FN=1020, P=0.624, R=0.627, F=0.626) - 2005-Intensive Care/09-Random Acts Of Kindness\n",
      "Eval: (N=2810, TP=2009, FP=801, FN=801, P=0.715, R=0.715, F=0.715) - 2005-Intensive Care/10-The Trouble With Me\n",
      "Eval: (N=2951, TP=2384, FP=567, FN=567, P=0.808, R=0.808, F=0.808) - 2005-Intensive Care/11-A Place To Crash\n",
      "Eval: (N=4018, TP=2088, FP=1930, FN=1930, P=0.520, R=0.520, F=0.520) - 2005-Intensive Care/12-King Of Bloke And Bird\n",
      "Total R: 0.5903521750754394\n",
      "Total P: 0.5211916080603507\n",
      "Total F: 0.5494243656511956\n"
     ]
    }
   ],
   "source": [
    "estimate_chords(sampler, model, device, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_chords(sampler, model, device, batch_size=8, result_dir=\"results/queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann_int, ann_lab = mir_eval.io.load_labeled_intervals(\"results/01-How Peculiar\")\n",
    "# pred_int, pred_lab = mir_eval.io.load_labeled_intervals(\"data/robbie_williams/chordlabs/2002-Escapology/01-How Peculiar.lab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(annotation_files, prediction_files):\n",
    "    assert len(annotation_files) == len(prediction_files)\n",
    "    assert len(annotation_files) > 0\n",
    "\n",
    "    scores = []\n",
    "    total_length = 0.\n",
    "\n",
    "    for af, pf in zip(annotation_files, prediction_files):\n",
    "        ann_int, ann_lab = mir_eval.io.load_labeled_intervals(af)\n",
    "        pred_int, pred_lab = mir_eval.io.load_labeled_intervals(pf)\n",
    "\n",
    "        # we assume that the end-time of the last annotated label is the\n",
    "        # length of the song\n",
    "        song_length = ann_int[-1][1]\n",
    "        total_length += song_length\n",
    "        \n",
    "#         est_intervals, est_labels = mir_eval.util.adjust_intervals(\n",
    "#             pred_int, pred_lab, ann_int.min(),\n",
    "#             ann_int.max(), mir_eval.chord.NO_CHORD,\n",
    "#             mir_eval.chord.NO_CHORD)\n",
    "#         assert len(ann_int) == len(pred_int)\n",
    "\n",
    "        scores.append(\n",
    "            (pf, song_length,\n",
    "             mir_eval.chord.evaluate(ann_int, ann_lab, pred_int, pred_lab))\n",
    "        )\n",
    "\n",
    "    return scores, total_length\n",
    "\n",
    "def average_scores(scores, total_length):\n",
    "    # initialise the average score with all metrics and values 0.\n",
    "    avg_score = {metric: 0. for metric in scores[0][-1]}\n",
    "\n",
    "    for _, length, score in scores:\n",
    "        weight = length / total_length\n",
    "        for metric in score:\n",
    "            avg_score[metric] += float(weight * score[metric])\n",
    "\n",
    "    return avg_score\n",
    "\n",
    "\n",
    "def compute_average_scores(annotation_files, prediction_files):\n",
    "    # first, compute all individual scores\n",
    "    scores, total_length = compute_scores(annotation_files, prediction_files)\n",
    "    return average_scores(scores, total_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_files(dir_path, excluded_files=()):\n",
    "    import os\n",
    "    import os.path\n",
    "    files = []\n",
    "    for root, dirs, filenames in os.walk(dir_path):\n",
    "        for filename in filenames:\n",
    "            if any(f in filename for f in excluded_files):\n",
    "                continue\n",
    "            if not filename.startswith('.'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                files.append(file_path)\n",
    "    return files\n",
    "\n",
    "def print_scores(scores):\n",
    "    for name, val in scores.items():\n",
    "        label = '\\t{}:'.format(name).ljust(16)\n",
    "        print(label + '{:.3f}'.format(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tthirds:        0.568\n",
      "\tthirds_inv:    0.547\n",
      "\ttriads:        0.555\n",
      "\ttriads_inv:    0.539\n",
      "\ttetrads:       0.534\n",
      "\ttetrads_inv:   0.522\n",
      "\troot:          0.624\n",
      "\tmirex:         0.567\n",
      "\tmajmin:        0.575\n",
      "\tmajmin_inv:    0.559\n",
      "\tsevenths:      0.555\n",
      "\tsevenths_inv:  0.542\n",
      "\tunderseg:      0.893\n",
      "\toverseg:       0.610\n",
      "\tseg:           0.610\n"
     ]
    }
   ],
   "source": [
    "#mir_eval.chord.evaluate(ann_int, ann_lab, pred_int, pred_lab)\n",
    "#mir_eval.chord.split(\"Bb7/#5\")\n",
    "excluded_files = (\"10-She's The One\", \"09-Knutsford City Limits\")\n",
    "#excluded_files = (\"03-You_Won_t_See_Me\", \"04-Nowhere_Man\", \"02-Dear_Prudence\")\n",
    "ann_root = \"data/robbie_williams/chordlabs/\"\n",
    "annotation_files = collect_files(ann_root, excluded_files)\n",
    "pred_root = \"results/robbie_williams/\"\n",
    "prediction_files = collect_files(pred_root, excluded_files)\n",
    "scores = compute_average_scores(annotation_files, prediction_files)\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
